% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/executeGA.R
\name{executeGA}
\alias{executeGA}
\title{executeGA}
\usage{
executeGA(
  savingName,
  omicData,
  subsetTrain,
  classVariable,
  idColumn,
  mlAlgorithm,
  numModelExecutions,
  bestLambda,
  predictorsToSelect,
  numTrees,
  mtry,
  splitRule,
  sampleFraction,
  maxDepth,
  minNodeSize,
  maximumChangePercentage,
  nIterations,
  nStopIter,
  populationSize,
  diagnosticChangeProbability,
  crossoverOperator,
  crossoverProbability,
  selectionOperator,
  mutationOperator,
  mutationProbability,
  nCores,
  seed
)
}
\arguments{
\item{savingName}{String | Name under which the model and solution will be saved after execution. If the user does not set any name, it will create a string with the current date.}

\item{omicData}{Dataset | Dataset of omic data that will be used.}

\item{subsetTrain}{Array of Integer | Subset of train samples.}

\item{classVariable}{String | Target variable, which must be binary, meaning it has two possible values. If the user does not specify a path to his own data, the value for the sample data, Ca.Co.Last, will be used.}

\item{idColumn}{String | Variable that indicates the identifier of each patient in both datasets. If the user does not specify a path to his own data, the value for the sample data, Trial, will be used.}

\item{mlAlgorithm}{String | Machine Learning algorithm to be applied, the options are: Lasso or RF (Random Forest). Default value: RF.}

\item{numModelExecutions}{Integer | Number of times the Lasso algorithm is executed. Default value: 5.}

\item{bestLambda}{Decimal/Bool | It indicates when to perform cv to find the best lambda for the Lasso model (Bool = FALSE) and when not (Decimal). If the value is FALSE, the best lambda found for the Baseline Lasso model will be used for all the Lasso models.}

\item{predictorsToSelect}{Integer | Number of predictors to be selected from the most important predictors ranked by the RF model. This parameter is a integer number between 1 and the total number of predictors in the data. Default value: 15.}

\item{numTrees}{Integer | Number of trees of the Random Forest model. Default value: 100.}

\item{mtry}{Integer | Number of predictors that are evaluated at each partition (node) of each tree. Default value: 225.}

\item{splitRule}{String | This is the rule used by the algorithm to select the predictor and the optimal value to separate a node into two branches during the tree construction. Default value: gini.}

\item{sampleFraction}{Decimal | Fraction of the training data that will be used to create each of the trees in the forest. Default value: 1.}

\item{maxDepth}{Integer | Maximum height of each tree in the forest. Default value: 4.}

\item{minNodeSize}{Integer | Minimum number of observations required in a node to be able to split it. Default value: 30.}

\item{maximumChangePercentage}{Decimal | Percentage (expressed as a fraction) indicating the maximum percentage of samples that can be changed. Default value: 0.2 (20%).}

\item{nIterations}{Integer | Number of iterations (generations) the genetic algorithm will perform. Default value: 200.}

\item{nStopIter}{Integer | Number of iterations after which the algorithm will stop if all of them have the same fitness value. Default value: 25.}

\item{populationSize}{Integer | Number of solutions that will be part of the initial population. Default value: 150.}

\item{diagnosticChangeProbability}{Decimal | Percentage (expressed as a fraction) indicating the probability of each gene in the solutions to be changed. Default value: 0.1 (10%).}

\item{crossoverOperator}{String | Crossover operator used in the genetic algorithm. Default value: Single Point Crossover.}

\item{crossoverProbability}{Decimal | Percentage (expressed as a fraction) indicating the probability of crossover occurrence. Default value: 0.8 (80%).}

\item{selectionOperator}{String | Selection operator used in the genetic algorithm. Default value: Tournament Selection.}

\item{mutationOperator}{String | Mutation operator used in the genetic algorithm. Default value: Random Mutation.}

\item{mutationProbability}{Decimal | Percentage (expressed as a fraction) indicating the probability of mutation occurrence. Default value: 0.1 (10%).}

\item{nCores}{Integer | Number of cores to be used in parallelization. Default value: 6.}

\item{seed}{Integer | Seed used for the creation of training and test sets. Default value: 1234.}
}
\description{
Methodology based on the combination of a genetic algorithm and a Machine Learning technique to mutate the final
diagnosis of patients, detecting anomalies in them.
}
\details{
These discrepancies may have their origin in the evolution of the subject itself, leading it from one group to
another in biological terms, or they may derive from human error in the labelling of the samples, among other causes.

This detection is done by combining a genetic algorithm and a machine learning algorithm, it is possible to use a Lasso model
or a Random Forest model.

A genetic algorithm is a technique inspired by biological evolution that simulates the process of natural selection and
evolution of species, the execution of a genetic algorithm starts with a randomly generated initial solution set.
- In this case, it is assumed that certain patients are misdiagnosed, so the initial solution set will be created by
randomly changing 10% of the patient diagnoses in each of these solutions.
In each generation (iteration) of the genetic algorithm, each of the solutions from the set of possible solutions is
used as a training dataset for the ML model, which will classify the patients and whose performance will determine the
fitness value (score) of the solution.
The way in which the score for each solution is calculated depends on the model used:
 - For the Lasso model, the score of each solution is defined by the average of the balanced accuracies obtained after
 training 5 Lasso models with that solution as training dataset.
- For RF model, the score of each solution is defined by the balanced accuracy obtained after training the RF model with
that solution as training dataset.
After this evaluation, a ranking of the solutions is created:
  - The two best solutions are combined to generate a new solution that is added to the set of possible solutions to the
  problem.
- Simultaneously, a certain number of the worst solutions are eliminated from the generation, i.e. they are no longer part
of the set of possible solutions to the problem.
This process is repeated for the specified number of generations, until a certain predefined threshold is reached in the
score of the solutions or until the value of the best score of the set of solutions is repeated for a certain specified
number of generations.
This procedure is used to determine which samples were anomalous. The genetic algorithm locates these anomalous samples
and the machine learning algorithm evidences this detection, validating that these samples belong to the alternative group.
}
\examples{

MLASDO::executeGA(mlAlgorithm = mlAlgorithm, numModelExecutions = numModelExecutions, bestLambda = bestLambda, predictorsToSelect = predictorsToSelect, numTrees = numTrees, mtry = mtry, splitRule = splitRule, sampleFraction = sampleFraction, maxDepth = maxDepth, minNodeSize = minNodeSize, omicData = omicData, subsetTrain = subsetTrain, classVariable = classVariable, idColumn = idColumn, savingName = savingName, nCores = nCores, maximumChangePercentage = maximumChangePercentage, nIterations = nIterations, nStopIter = nStopIter, populationSize = populationSize, diagnosticChangeProbability = diagnosticChangeProbability, crossoverOperator = crossoverOperator, crossoverProbability = crossoverProbability, selectionOperator = selectionOperator, mutationOperator = mutationOperator, mutationProbability = mutationProbability, seed = seed)
}
